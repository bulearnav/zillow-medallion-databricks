{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "539cad1a-3175-458e-a9d3-e9ea48e17825",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .csv(\"dbfs:/Volumes/zillow/zillow_medallion/raw/State_time_series.csv\")\n",
    ")\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6523a480-66df-4803-8023-4b278a658487",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "entry_count = df.count()\n",
    "print(\"Number of entries in df:\", entry_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd9fd74-38c7-490a-9e70-2db23bf4a728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "RAW = \"/Volumes/zillow/zillow_medallion/raw\"\n",
    "OUT_FILE = \"/Volumes/zillow/zillow_medallion/raw-converted_format/xml/State_time_series.xml\"\n",
    "OUT_DIR = \"/Volumes/zillow/zillow_medallion/raw-converted_format/xml\"\n",
    "TMP_DIR = \"/Volumes/zillow/zillow_medallion/raw-converted_format/xml/_tmp_state_xml\"\n",
    "\n",
    "src = f\"{RAW}/State_time_series.csv\"\n",
    "\n",
    "# Clean output\n",
    "dbutils.fs.mkdirs(\"dbfs:\" + OUT_DIR)\n",
    "try: dbutils.fs.rm(\"dbfs:\" + OUT_FILE, True)\n",
    "except: pass\n",
    "dbutils.fs.rm(\"dbfs:\" + TMP_DIR, True)\n",
    "\n",
    "df = (spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(src))\n",
    "\n",
    "# Row-wise flat XML as text lines: <row><col>..</col>...</row>\n",
    "xml_df = df.select(\n",
    "    F.concat(\n",
    "        F.lit(\"<row>\"),\n",
    "        F.concat_ws(\"\", *[\n",
    "            F.concat(\n",
    "                F.lit(f\"<{c}>\"),\n",
    "                F.coalesce(F.col(c).cast(\"string\"), F.lit(\"\")),\n",
    "                F.lit(f\"</{c}>\")\n",
    "            )\n",
    "            for c in df.columns\n",
    "        ]),\n",
    "        F.lit(\"</row>\")\n",
    "    ).alias(\"value\")\n",
    ")\n",
    "\n",
    "# write.text writes a folder; we rename the single part file to .xml\n",
    "xml_df.coalesce(1).write.mode(\"overwrite\").text(TMP_DIR)\n",
    "\n",
    "files = dbutils.fs.ls(\"dbfs:\" + TMP_DIR)\n",
    "part_file = [f.path for f in files if f.name.startswith(\"part-\") and f.name.endswith(\".txt\")][0]\n",
    "\n",
    "dbutils.fs.mv(part_file, \"dbfs:\" + OUT_FILE, True)\n",
    "dbutils.fs.rm(\"dbfs:\" + TMP_DIR, True)\n",
    "\n",
    "print(\"Wrote XML:\", OUT_FILE)\n",
    "display(dbutils.fs.ls(\"dbfs:\" + OUT_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb644c1e-5747-41ad-91b5-dad7b4fe1498",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_xml = spark.read.text(\"dbfs:/Volumes/zillow/zillow_medallion/raw-converted_format/xml/State_time_series.xml\")\n",
    "display(df_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47eeac08-bdc5-4d04-8bd3-1f6427d29423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "entry_count = df_xml.count()\n",
    "print(\"Number of entries in df_xml:\", entry_count)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "XML Conversion and loading",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
